# Chat KTR에서 사용하는 모델 정보

## ❌ 우리가 하지 않는 것: Text Generation (생성)

현재 시스템은 **텍스트를 생성하지 않습니다!**

```
사용자: "MIS 설치해줘"
  ↓
시스템: [검색] → "MIS 설치해주세요" 찾음 → 엑셀의 답변 그대로 반환
  ↓
답변: "MIS 설치 - 그룹웨어 게시판 > ..." (엑셀에 있는 그대로!)
```

---

## ✅ 우리가 사용하는 것: OpenAI Embedding API

### 1. 모델 이름
**`text-embedding-3-small`** (OpenAI, 2024년 1월 출시)

### 2. 모델 스펙

| 항목 | 값 |
|------|-----|
| **출력 차원** | 1536 차원 |
| **최대 입력** | 8191 토큰 (~25,000자) |
| **가격** | $0.02 / 1M 토큰 |
| **속도** | 매우 빠름 (~0.3초) |
| **용도** | 의미 검색, 분류, 추천 |

### 3. 코드에서 사용하는 부분

```python
# rag_chatbot_v2.py - line 139~142
response = self.client.embeddings.create(
    model="text-embedding-3-small",  # ← 여기!
    input=normalized_question
)
embedding = response.data[0].embedding  # [0.234, 0.567, ..., 0.891] (1536개)
```

---

## 📚 OpenAI Embedding 모델의 학습 방법

### 아키텍처
OpenAI는 정확한 아키텍처를 공개하지 않았지만, 다음과 같이 추정됩니다:

1. **기반 모델**: Transformer 기반 (BERT/GPT 계열)
2. **학습 방식**: Contrastive Learning (대조 학습)

### 학습 과정 (추정)

#### Phase 1: Pre-training (사전 학습)
```
입력: 인터넷의 방대한 텍스트 데이터 (수십억 개 문서)
목표: 언어의 의미를 이해하는 법 학습

예시:
- "고양이"와 "개"는 비슷한 벡터 (둘 다 동물)
- "고양이"와 "자동차"는 먼 벡터 (관련 없음)
```

#### Phase 2: Contrastive Learning (대조 학습)
```
학습 데이터: (질문, 정답, 오답) 삼중쌍

예시:
질문: "파이썬으로 파일 읽기"
정답: "with open('file.txt') as f: ..."  ← 가깝게
오답: "자바 설치 방법"                   ← 멀게

손실 함수:
- 질문과 정답의 유사도는 높게 (cosine similarity → 1)
- 질문과 오답의 유사도는 낮게 (cosine similarity → 0)
```

#### Phase 3: Fine-tuning (미세 조정)
```
목표: 특정 작업에 최적화

학습 데이터:
- 검색 쿼리 - 클릭한 문서 쌍
- Q&A 데이터셋
- 번역 쌍 (다국어)
```

---

## 🔬 핵심 기술: Contrastive Learning

### 개념
"비슷한 것은 가깝게, 다른 것은 멀게"

### 수학적 표현

```
입력: (Anchor, Positive, Negative)
- Anchor: 기준 텍스트 (예: 사용자 질문)
- Positive: 관련 있는 텍스트 (예: 정답)
- Negative: 관련 없는 텍스트 (예: 오답)

손실 함수 (Triplet Loss):
L = max(0, d(A, P) - d(A, N) + margin)

여기서:
- d(A, P): Anchor와 Positive 사이 거리 (작아야 함)
- d(A, N): Anchor와 Negative 사이 거리 (커야 함)
- margin: 최소 간격 (예: 0.2)
```

### 예시

```python
# 학습 전
"MIS 설치" → [0.1, 0.2, 0.3, ...]
"MIS 설치 방법" → [0.9, 0.8, 0.7, ...]  # 전혀 비슷하지 않음!

# 학습 후
"MIS 설치" → [0.234, 0.567, 0.891, ...]
"MIS 설치 방법" → [0.239, 0.563, 0.885, ...]  # 매우 비슷함! (유사도 0.95)
```

---

## 🎯 우리 시스템에서의 작동

### 1. 초기화 (1회만)
```python
# 27개 질문 모두 임베딩
"MIS 설치해주세요" → [0.234, 0.567, ..., 0.891]
"암호를 재설정하고 싶어요" → [0.123, 0.456, ..., 0.789]
...
```

### 2. 검색 (질문마다)
```python
# 사용자 질문 임베딩
"mis 설치" → [0.239, 0.563, ..., 0.885]

# 코사인 유사도 계산
유사도("mis 설치", "MIS 설치해주세요") = 0.941  ← 매우 높음!
유사도("mis 설치", "암호 재설정") = 0.234       ← 낮음

# 가장 높은 유사도의 답변 반환
→ "MIS 설치 - 그룹웨어 게시판 > ..."
```

---

## 🆚 Fine-tuning vs Embedding (우리 선택)

### Fine-tuning (우리가 하지 않은 것)
```
필요 데이터: 수천 ~ 수만 개
비용: GPU 필요 ($$$$)
시간: 수 시간 ~ 며칠
결과: 새로운 텍스트 생성 가능
문제: 
  - 데이터 27개로는 불가능
  - "환각(hallucination)" 발생 가능
  - 업데이트 어려움 (재학습 필요)
```

### Embedding + Search (우리 선택)
```
필요 데이터: 27개로 충분!
비용: API 호출만 ($0.02 / 1M 토큰)
시간: 초기화 8초, 검색 0.3초
결과: 엑셀 데이터 그대로 반환 (정확!)
장점:
  - 적은 데이터로 가능
  - 정확한 답변 (엑셀 그대로)
  - 업데이트 쉬움 (엑셀만 수정)
```

---

## 📊 실제 성능

### 우리 시스템 테스트 결과

```
질문: "mis 설치해줘"
→ 검색: "MIS 설치해주세요" (유사도: 0.941)
→ 답변: ✅ 정확한 답변 반환

질문: "전화할때 주의할점"
→ 검색: "전화" (유사도: 0.821)
→ 답변: ✅ 전화 예절 답변 반환

질문: "WiFi 비밀번호"
→ 검색: 유사한 질문 없음 (최대 유사도: 0.234)
→ 답변: ❌ "정보를 찾을 수 없습니다" → 자동 로깅
```

---

## 🔑 핵심 요약

1. **우리는 Generation 안 함!**
   - ChatGPT처럼 텍스트 생성 ❌
   - 엑셀 데이터 검색만 ✅

2. **사용 모델: OpenAI `text-embedding-3-small`**
   - 텍스트를 1536차원 벡터로 변환
   - Contrastive Learning으로 학습됨
   - 의미가 비슷하면 벡터도 비슷함

3. **왜 이 방식?**
   - 데이터 27개로 충분
   - 정확한 답변 (엑셀 그대로)
   - 저렴하고 빠름
   - 업데이트 쉬움

4. **단점**
   - 엑셀에 없는 질문은 답변 불가
   - 창의적인 답변 불가
   - 질문을 다양하게 표현해도 찾을 수 있지만, 너무 다르면 못 찾음

---

## 참고 자료

- OpenAI Embeddings Guide: https://platform.openai.com/docs/guides/embeddings
- Text-embedding-3 Release: https://openai.com/blog/new-embedding-models-and-api-updates
- Contrastive Learning: https://arxiv.org/abs/2002.05709







